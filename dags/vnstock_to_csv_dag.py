from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import pandas as pd
from vnstock import Vnstock 
import os

# --- 1. C·∫•u h√¨nh DAG v√† Bi·∫øn C·ª•c b·ªô ---

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2026, 1, 1),
    'email': ['tbuiquang103@gmail.com'],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}


TICKERS = ['FPT', 'HPG', 'VCB', 'GAS', 'VNM', 'MSN', 'MWG', 'VPB', 'TCB', 'ACB'] 

BASE_DATA_PATH = '/usr/local/airflow/dags/data_lake/vnstock_prices_csv' 

with DAG(
    'vnstock_to_csv_etl',
    default_args=default_args,
    description='ETL gi√° ch·ª©ng kho√°n VN30 t·ª´ vnstock v√† l∆∞u v√†o CSV Data Lake',
    schedule='0 17 * * 1-5',  # Ch·∫°y l√∫c 17:00 t·ª´ T2 ƒë·∫øn T6
    catchup=False,
    tags=['finance', 'vnstock', 'csv'],
) as dag:
    
    def extract_close_price(**kwargs):
        """T·∫£i gi√° l·ªãch s·ª≠ (O, H, L, C, V) c·ªßa ng√†y ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh."""
        
        execution_date = kwargs['ds'] 
        data = []
        
        vnstock_api = Vnstock()
        
        for ticker in TICKERS:
            try:
                stock_obj = vnstock_api.stock(symbol=ticker, source="VCI")
                

                df = stock_obj.quote.history(
                    start=execution_date, 
                    end=execution_date, 
                    interval="1D"
                )
                
                if not df.empty:
                    
                    if 'time' in df.columns:
                        df.rename(columns={'time': 'Date'}, inplace=True)
                    elif 'TradingDate' in df.columns:
                        df.rename(columns={'TradingDate': 'Date'}, inplace=True)

                    if 'Date' in df.columns:
                        df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')
                    
                    print(f"DEBUG: C√°c c·ªôt DF tr∆∞·ªõc khi XCom: {df.columns.tolist()}") 
                    
                    # =================================================================
                    
                    latest_row = df.iloc[-1].to_dict() 
                    
                    latest_row['Ticker'] = ticker
                    if 'Date' not in latest_row:
                        latest_row['Date'] = execution_date 
                    
                    data.append(latest_row)
                    print(f" T·∫£i th√†nh c√¥ng {ticker} cho ng√†y {execution_date}")
                else:
                    print(f"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu cho {ticker} v√†o ng√†y {execution_date}")
            except Exception as e:
                print(f" L·ªói khi t·∫£i {ticker}: {e}")
                
        final_df = pd.DataFrame(data)
        print(f"T√™n c·ªôt DataFrame cu·ªëi c√πng: {final_df.columns.tolist()}") 
        
        return final_df 
    
    extract_task = PythonOperator(
        task_id='extract_close_price',
        python_callable=extract_close_price,
        do_xcom_push=True,
    )


    def load_to_csv_data_lake(**kwargs):
        """L·∫•y d·ªØ li·ªáu t·ª´ XCom v√† l∆∞u d∆∞·ªõi d·∫°ng CSV ph√¢n v√πng."""
        
        ti = kwargs['ti']
        df = ti.xcom_pull(task_ids='extract_close_price')
        
        if df is None or df.empty:
            print(" Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ l∆∞u tr·ªØ. B·ªè qua.")
            return

        date_column = 'Date' 
        
        df[date_column] = pd.to_datetime(df[date_column]) 
        
        df['year'] = df[date_column].dt.year
        df['month'] = df[date_column].dt.month
        
        rows_saved = 0
        
        # Ph√¢n v√πng v√† l∆∞u tr·ªØ
        for ticker in df['Ticker'].unique():
            df_ticker = df[df['Ticker'] == ticker]
            
            # ƒê·ªãnh d·∫°ng ƒë∆∞·ªùng d·∫´n theo ph√¢n v√πng (ticker/year/month/date.csv)
            date_str = df_ticker[date_column].iloc[0].strftime('%Y-%m-%d')
            year = df_ticker['year'].iloc[0]
            month = df_ticker['month'].iloc[0]

            save_dir = os.path.join(
                BASE_DATA_PATH, 
                ticker, 
                str(year), 
                str(month).zfill(2) 
            )
            save_path = os.path.join(save_dir, f"{date_str}.csv")
            
            # T·∫°o th∆∞ m·ª•c v√† L∆∞u tr·ªØ
            os.makedirs(save_dir, exist_ok=True)
            df_ticker.to_csv(save_path, index=False)
            print(f"üíæ L∆∞u tr·ªØ th√†nh c√¥ng {ticker} t·∫°i {save_path}")
            rows_saved += len(df_ticker)
        
        return rows_saved

    load_task = PythonOperator(
        task_id='load_to_csv_data_lake',
        python_callable=load_to_csv_data_lake,
    )
    
    def data_quality_check(**kwargs):
        """Ki·ªÉm tra: Null, Gi√° tr·ªã d∆∞∆°ng, v√† s·ªë l∆∞·ª£ng d√≤ng."""
        
        ti = kwargs['ti']
        df = ti.xcom_pull(task_ids='extract_close_price')
        rows_loaded = ti.xcom_pull(task_ids='load_to_csv_data_lake')
        
        if df is None or df.empty:
            print(" DQ Check b·ªã b·ªè qua: D·ªØ li·ªáu tr·ªëng.")
            return
        
        df.columns = [col.lower() for col in df.columns] 
        
        required_columns = ['close', 'open', 'high', 'low', 'volume']
        
        if df[required_columns].isnull().any().any():
            raise ValueError("DQ Check th·∫•t b·∫°i: C√≥ gi√° tr·ªã Null trong c√°c c·ªôt gi√° tr·ªã.")

        if (df['close'] <= 0).any():
            raise ValueError("DQ Check th·∫•t b·∫°i: Gi√° ƒë√≥ng c·ª≠a c√≥ gi√° tr·ªã <= 0.")
            
        if len(df) != rows_loaded:
            raise ValueError(f"DQ Check th·∫•t b·∫°i: S·ªë d√≤ng t·∫£i v·ªÅ ({len(df)}) kh√°c s·ªë d√≤ng ƒë√£ l∆∞u ({rows_loaded}).")
        
        print(f" Ki·ªÉm tra Ch·∫•t l∆∞·ª£ng D·ªØ li·ªáu th√†nh c√¥ng cho {len(df)} d√≤ng d·ªØ li·ªáu.")

    dq_task = PythonOperator(
        task_id='data_quality_check',
        python_callable=data_quality_check,
    )

    extract_task >> load_task >> dq_task